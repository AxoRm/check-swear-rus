{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894545b1",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "`check-swear` is a machine learning and regular expression-based library designed to detect and filter profanity in text-based communication. Initially aimed at monitoring and improving the language used in school and student chats, `check-swear` offers a versatile solution that can be integrated into various environments requiring profanity filtering.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Machine Learning Driven**: Utilizes SVM classification algorithm to understand context and nuances, ensuring high accuracy in detecting offensive language.\n",
    "- **Regular Expression Support**: Incorporates a comprehensive set of regular expressions to catch commonly used profane words and phrases.\n",
    "- **Customizable Filters**: Offers the flexibility to customize and extend the list of profane words based on the specific needs of different user groups or cultural sensitivities.\n",
    "- **Easy Integration**: Designed with simplicity in mind, SwearCheck can be easily integrated into chat applications, forums, and any platform requiring content moderation.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "To get started with `check-swear`, simply install the package via pip:\n",
    "\n",
    "```bash\n",
    "pip install check-swear\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf227f37",
   "metadata": {},
   "source": [
    "### Note on Importing the Library\n",
    "Despite the library being named check-swear, when you import it into your Python project, you will need to replace the hyphen (-) with an underscore (_) This is a common convention in Python packaging because Python modules and packages cannot have hyphens in their names. The hyphen is not a valid character for Python identifiers, so it's replaced with an underscore for the actual package name.\n",
    "\n",
    "```python\n",
    "import check_swear\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1529b13",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615f53b",
   "metadata": {},
   "source": [
    "```python\n",
    "from check_swear import SwearingCheck\n",
    "\n",
    "sch = SwearingCheck() # create filter\n",
    "\n",
    "rude_comment = \"а не пошел бы ты нахуй, дружище\"\n",
    "friendly_comment = \"svm - алгоритм машинного обучения\"\n",
    "\n",
    "sch.predict(rude_comment)\n",
    "# [1]\n",
    "\n",
    "sch.predict_proba(rude_comment)\n",
    "# [0.9822432776183899]\n",
    "\n",
    "sch.predict(friendly_comment)\n",
    "# [0]\n",
    "\n",
    "sch.predict_proba(friendly_comment)\n",
    "# [0.027772391001567764]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c776b",
   "metadata": {},
   "source": [
    "### Model and Regular Expression Checks\n",
    "The library utilizes a pre-trained SVM (Support Vector Machine) model for profanity detection, which is adept at classifying text but isn't flawless. To enhance accuracy, each comment undergoes a preliminary scan with two sets of regular expressions before the machine learning model processes it. These regex checks aim to catch clear profanity patterns. If you wish to bypass this regex pre-check for any reason, you can set the reg_pred=False parameter when using the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85620242",
   "metadata": {},
   "source": [
    "```python\n",
    "clear_ml_sch = SwearingCheck(reg_pred=False)\n",
    "\n",
    "hard2detect = \"а вот это охуеньчик))\"\n",
    "\n",
    "clear_ml_sch.predict_proba(hard2detect)\n",
    "# [0.02542796]\n",
    "\n",
    "sch.predict_proba(hard2detect)\n",
    "# [0.5127139801037626]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba656f",
   "metadata": {},
   "source": [
    "_Understanding Probability Scores:_ Even benign comments sometimes contain character sequences that resemble profane words, which could lead the filter to assign a roughly 30% probability of the comment being offensive. It's a cautious indicator, hinting at potential profanity without outright condemnation. If the regular expression engine detects a match in our default list or any custom list you supply, the probability jumps to around 50%, reflecting a stronger suspicion. Keep in mind that despite the robust training on over 700,000 comments, the nuances of language and the ever-evolving lexicon of slang can sometimes elude even the most sophisticated models. We are committed to continuously expanding our dataset of profane words and phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d24b6",
   "metadata": {},
   "source": [
    "### Additional Features of check-swear\n",
    "\n",
    "*   **Custom Stop Words List:** Enhance regular expression detection by adding your own list of stop words.\n",
    "    \n",
    "*   **Flexible Input Formats:** The model accepts both single strings and lists of strings for analysis.\n",
    "    \n",
    "*   **Bin Parameter:** Divide large texts into manageable `bins` parts for efficient processing.\n",
    "\n",
    "*   **Transliteration Support**: The library understands transliteration, recognizing Russian words written with English letters, making it robust in handling a variety of text inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be1e85",
   "metadata": {},
   "source": [
    "```python\n",
    "adv_sch = SwearingCheck(reg_pred=True, bins=3, stop_words=[\"питон\"])\n",
    "\n",
    "long_comment = \"буду с тобой асболютно честен но твой проект на питоне это просто абсолютно полная hueta..\"\n",
    "\n",
    "adv_sch.predict_proba(long_comment)\n",
    "# [0.02110824940143035, 0.5090685358094555, 0.9741733209291503]\n",
    "\n",
    "adv_sch.output_text_\n",
    "# ['буду с тобой асболютно честен', 'но твой проект на питоне', 'это просто абсолютно полная hueta..']\n",
    "\n",
    "# array of strings\n",
    "array_comment = [\"всем привет\", \"ты s__УкА blYa\"]\n",
    "\n",
    "adv_sch.predict_proba(array_comment)\n",
    "# [0.023436897211045367, 0.9999479672960417]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790d3c8",
   "metadata": {},
   "source": [
    "### Conclusion on Model Limitations:\n",
    "\n",
    "Please be aware that while `check-swear` is a robust tool for identifying profane content, it is not without limitations. Creative individuals may always find novel ways to bypass filters with new slang or coded language. Despite this, `check-swear` effectively identifies the majority of profane comments (about 0.95 F1 score), helping maintain a respectful and professional discourse in various settings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
